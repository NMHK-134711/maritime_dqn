{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5638f602-8909-45a4-8978-92ca5a44481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 디바이스: cuda\n",
      "모델 파일 'C:\\baramproject\\trained_model\\sibal12\\navigation_model_3.pth'가 없습니다. 새로 학습을 시작합니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85640760d1b425dac7ac6d3c1f0880e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "학습 진행률:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_100.png\n",
      "Episode 200 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_200.png\n",
      "Episode 300 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_300.png\n",
      "Episode 400 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_400.png\n",
      "Episode 500 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_500.png\n",
      "Episode 600 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_600.png\n",
      "Episode 700 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_700.png\n",
      "Episode 800 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_800.png\n",
      "Episode 900 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_900.png\n",
      "Episode 1000 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1000.png\n",
      "Episode 1100 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1100.png\n",
      "Episode 1200 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1200.png\n",
      "Episode 1300 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1300.png\n",
      "Episode 1400 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1400.png\n",
      "Episode 1500 - 중간 경로 시각화 (Start: (18, 219), End: (248, 69))\n",
      "이미지 저장: C:\\baramproject\\trained_model\\sibal12\\episode_3_debug\\episode_1500.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 333\u001b[0m\n\u001b[0;32m    330\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state_tensor\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size:\n\u001b[1;32m--> 333\u001b[0m     batch, idxs, is_weights \u001b[38;5;241m=\u001b[39m \u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     states, actions, rewards_batch, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m    336\u001b[0m     states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(states)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[29], line 254\u001b[0m, in \u001b[0;36mPrioritizedReplayBuffer.sample\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    251\u001b[0m is_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mn_entries \u001b[38;5;241m*\u001b[39m sampling_probabilities, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\n\u001b[0;32m    252\u001b[0m is_weights \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m is_weights\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch, idxs, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# CUDA 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 디바이스: {device}\")\n",
    "\n",
    "# 1. 그리드 맵 로드\n",
    "grid = np.load(r'C:/baramproject/sibal/land_sea_grid_cartopy_downsized.npy')\n",
    "n_rows, n_cols = grid.shape  # 270x236\n",
    "\n",
    "# 2. 좌표 변환 함수\n",
    "def latlon_to_grid(lat, lon, lat_min=30, lat_max=38, lon_min=120, lon_max=127):\n",
    "    row = int((lat_max - lat) / (lat_max - lat_min) * n_rows)\n",
    "    col = int((lon - lon_min) / (lon_max - lon_min) * n_cols)\n",
    "    return min(max(row, 0), n_rows-1), min(max(col, 0), n_cols-1)\n",
    "\n",
    "# 시작점과 도착점 설정\n",
    "start_lat, start_lon = 37.46036, 126.52360  # 인천항\n",
    "end_lat, end_lon = 30.62828, 122.06400     # 상하이항\n",
    "start_pos = latlon_to_grid(start_lat, start_lon)\n",
    "end_pos = latlon_to_grid(end_lat, end_lon)\n",
    "\n",
    "# 3. 유클리드 거리 계산 함수\n",
    "def euclidean_distance(pos1, pos2):\n",
    "    return np.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "\n",
    "# 4. 조류 데이터 로드 함수\n",
    "def load_tidal_data(time_str):\n",
    "    file_path = f\"C:/baramproject/tidal_database/tidal_{time_str}.json\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"파일 {file_path}가 존재하지 않습니다.\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['result']['data']\n",
    "\n",
    "# 5. 조류 데이터를 그리드에 매핑\n",
    "def map_tidal_to_grid(tidal_data, n_rows, n_cols):\n",
    "    current_grid = np.zeros((n_rows, n_cols, 2))  # [방향, 속도]\n",
    "    for entry in tidal_data:\n",
    "        lat = float(entry['pre_lat'])\n",
    "        lon = float(entry['pre_lon'])\n",
    "        row, col = latlon_to_grid(lat, lon)\n",
    "        if 0 <= row < n_rows and 0 <= col < n_cols and grid[row, col] == 0:\n",
    "            direction = float(entry['current_dir'])\n",
    "            speed = float(entry['current_speed'])\n",
    "            current_grid[row, col] = [direction, speed]\n",
    "    return current_grid\n",
    "\n",
    "# 6. 환경 클래스 정의\n",
    "class NavigationEnv:\n",
    "    def __init__(self, grid, start_pos, end_pos, tidal_database_path, max_steps=300, step_time_minutes=12):\n",
    "        self.grid = grid\n",
    "        self.start_pos = start_pos\n",
    "        self.end_pos = end_pos\n",
    "        self.current_pos = start_pos\n",
    "        self.actions = [(-1,0), (1,0), (0,-1), (0,1), (-1,-1), (-1,1), (1,-1), (1,1)]\n",
    "        self.visit_count = {}\n",
    "        self.prev_action = None\n",
    "        self.tidal_database_path = tidal_database_path\n",
    "        self.max_steps = max_steps  # 300 스탭\n",
    "        self.step_time_minutes = step_time_minutes  # 스탭당 12분\n",
    "        self.current_time = None\n",
    "        self.current_tidal_data = None\n",
    "        self.cumulative_time = 0  # 누적 시간 (분 단위)\n",
    "\n",
    "    def reset(self, start_time=None):\n",
    "        if start_time is None:\n",
    "            start_time = self._random_start_time()\n",
    "        self.current_pos = self.start_pos\n",
    "        self.visit_count = {}\n",
    "        self.prev_action = None\n",
    "        self.current_time = start_time\n",
    "        self.cumulative_time = 0\n",
    "        tidal_data = load_tidal_data(self.current_time.strftime(\"%Y%m%d_%H%M\"))\n",
    "        self.current_tidal_data = map_tidal_to_grid(tidal_data, n_rows, n_cols)\n",
    "        return self.get_state()\n",
    "\n",
    "    def _random_start_time(self):\n",
    "        start_datetime = datetime(2018, 1, 1, 0, 0)\n",
    "        end_datetime = datetime(2018, 12, 28, 0, 0)\n",
    "        total_minutes = int((end_datetime - start_datetime).total_seconds() / 60)\n",
    "        random_minutes = random.randint(0, total_minutes // 30) * 30\n",
    "        return start_datetime + timedelta(minutes=random_minutes)\n",
    "\n",
    "    def get_state(self):\n",
    "        # 상태를 상대 좌표 기반으로 재정의 (절대 좌표 제거)\n",
    "        dx = self.end_pos[0] - self.current_pos[0]\n",
    "        dy = self.end_pos[1] - self.current_pos[1]\n",
    "        angle_to_goal = math.atan2(dy, dx) if (dx, dy) != (0, 0) else 0\n",
    "        prev_action_idx = self.actions.index(self.prev_action) if self.prev_action else -1\n",
    "        row, col = self.current_pos\n",
    "        if 0 <= row < n_rows and 0 <= col < n_cols:\n",
    "            current_dir = self.current_tidal_data[row, col, 0] * math.pi / 180\n",
    "            current_speed = self.current_tidal_data[row, col, 1]\n",
    "        else:\n",
    "            current_dir, current_speed = 0, 0\n",
    "        return (dx, dy, angle_to_goal, prev_action_idx, current_dir, current_speed)  # 6차원 상태\n",
    "\n",
    "    def step(self, action):\n",
    "        move = self.actions[action]\n",
    "        new_pos = (self.current_pos[0] + move[0], self.current_pos[1] + move[1])\n",
    "\n",
    "        if (0 <= new_pos[0] < n_rows and 0 <= new_pos[1] < n_cols and self.grid[new_pos] == 0):\n",
    "            prev_dist = euclidean_distance(self.current_pos, self.end_pos)\n",
    "            self.current_pos = new_pos\n",
    "            new_dist = euclidean_distance(self.current_pos, self.end_pos)\n",
    "\n",
    "            dist_change = prev_dist - new_dist\n",
    "            reward = dist_change * 100 - 5  # 거리 감소 보상 및 스탭 페널티\n",
    "\n",
    "            # 조류 보상/페널티\n",
    "            row, col = self.current_pos\n",
    "            current_dir = self.current_tidal_data[row, col, 0] * math.pi / 180\n",
    "            current_speed = self.current_tidal_data[row, col, 1]\n",
    "            move_angle = math.atan2(move[1], move[0])\n",
    "            angle_diff = abs((current_dir - move_angle + math.pi) % (2 * math.pi) - math.pi)\n",
    "            if angle_diff < math.pi / 4:\n",
    "                reward += current_speed * 0.5\n",
    "            elif angle_diff > 3 * math.pi / 4:\n",
    "                reward -= current_speed * 0.7\n",
    "\n",
    "            # 역방향 이동 및 반복 방문 페널티\n",
    "            if dist_change < 0:\n",
    "                reward -= 200\n",
    "            pos_tuple = tuple(self.current_pos)\n",
    "            self.visit_count[pos_tuple] = self.visit_count.get(pos_tuple, 0) + 1\n",
    "            if self.visit_count[pos_tuple] > 3:\n",
    "                reward -= 20 * (self.visit_count[pos_tuple] - 3)\n",
    "\n",
    "            # 종료 조건\n",
    "            if new_dist < 2:\n",
    "                reward += 1000\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "\n",
    "            self.prev_action = move\n",
    "            self.cumulative_time += self.step_time_minutes\n",
    "            if self.cumulative_time >= 30:  # 30분마다 조류 데이터 갱신\n",
    "                self.current_time += timedelta(minutes=30)\n",
    "                tidal_data = load_tidal_data(self.current_time.strftime(\"%Y%m%d_%H%M\"))\n",
    "                self.current_tidal_data = map_tidal_to_grid(tidal_data, n_rows, n_cols)\n",
    "                self.cumulative_time -= 30\n",
    "        else:\n",
    "            reward = -20  # 충돌 페널티\n",
    "            done = False\n",
    "\n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "# 7. DQN 모델 정의 (입력 차원 6으로 변경)\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim=6, output_dim=8):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# 8. SumTree 클래스 정의 (변경 없음)\n",
    "class SumTree:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.write = 0\n",
    "        self.n_entries = 0\n",
    "\n",
    "    def _propagate(self, idx, change):\n",
    "        parent = (idx - 1) // 2\n",
    "        self.tree[parent] += change\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    def _retrieve(self, idx, s):\n",
    "        left = 2 * idx + 1\n",
    "        right = left + 1\n",
    "        if left >= len(self.tree):\n",
    "            return idx\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    def add(self, priority, data):\n",
    "        idx = self.write + self.capacity - 1\n",
    "        self.data[self.write] = data\n",
    "        self.update(idx, priority)\n",
    "        self.write = (self.write + 1) % self.capacity\n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    def update(self, idx, priority):\n",
    "        change = priority - self.tree[idx]\n",
    "        self.tree[idx] = priority\n",
    "        self._propagate(idx, change)\n",
    "\n",
    "    def get(self, s):\n",
    "        idx = self._retrieve(0, s)\n",
    "        data_idx = idx - self.capacity + 1\n",
    "        return idx, self.tree[idx], self.data[data_idx]\n",
    "\n",
    "# 9. PrioritizedReplayBuffer 클래스 정의 (변경 없음)\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.5, beta=0.6):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.alpha = alpha  # 우선순위 중요도\n",
    "        self.beta = beta    # 샘플링 편향 보정\n",
    "        self.epsilon = 0.01\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        data = (state, action, reward, next_state, done)\n",
    "        if done:\n",
    "            priority = 100.0\n",
    "        else:\n",
    "            priority = np.max(self.tree.tree[-self.tree.capacity:]) if self.tree.n_entries > 0 else 1.0\n",
    "        self.tree.add(priority, data)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = []\n",
    "        idxs = []\n",
    "        segment = self.tree.total() / batch_size\n",
    "        priorities = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a, b = segment * i, segment * (i + 1)\n",
    "            s = random.uniform(a, b)\n",
    "            idx, p, data = self.tree.get(s)\n",
    "            batch.append(data)\n",
    "            idxs.append(idx)\n",
    "            priorities.append(p)\n",
    "\n",
    "        sampling_probabilities = np.array(priorities) / self.tree.total()\n",
    "        is_weights = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weights /= is_weights.max()\n",
    "\n",
    "        return batch, idxs, torch.tensor(is_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    def update(self, idxs, errors):\n",
    "        for idx, error in zip(idxs, errors):\n",
    "            p = (abs(error) + self.epsilon) ** self.alpha\n",
    "            self.tree.update(idx, p)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tree.n_entries\n",
    "\n",
    "# 10. 학습 설정\n",
    "tidal_database_path = r\"C:\\baramproject\\tidal_database\"\n",
    "env = NavigationEnv(grid, start_pos, end_pos, tidal_database_path, max_steps=300)\n",
    "model = DQN(6, 8).to(device)  # 입력 차원 6으로 변경\n",
    "target_model = DQN(6, 8).to(device)\n",
    "\n",
    "# 모델 로드 또는 새로 초기화\n",
    "model_path = r'C:\\baramproject\\trained_model\\sibal12\\navigation_model_3.pth'\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "        print(f\"기존 모델 '{model_path}'를 불러왔습니다. 재학습을 시작합니다.\")\n",
    "        epsilon = 0.5\n",
    "        num_episodes = 300\n",
    "    except Exception as e:\n",
    "        print(f\"모델 로드 실패: {e}. 새로 학습을 시작합니다.\")\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "        epsilon = 1.0\n",
    "        num_episodes = 2000\n",
    "else:\n",
    "    print(f\"모델 파일 '{model_path}'가 없습니다. 새로 학습을 시작합니다.\")\n",
    "    target_model.load_state_dict(model.state_dict())\n",
    "    epsilon = 1.0\n",
    "    num_episodes = 5000\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "replay_buffer = PrioritizedReplayBuffer(20000)  # capacity\n",
    "batch_size = 128\n",
    "gamma = 0.99\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "\n",
    "# 이미지 저장 디렉토리 설정\n",
    "save_dir = r'C:\\baramproject\\trained_model\\sibal12\\episode_3_debug'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    print(f\"디렉토리 '{save_dir}'를 생성했습니다.\")\n",
    "\n",
    "# 11. 학습 루프\n",
    "rewards = []\n",
    "path_lengths = []\n",
    "progress_bar = tqdm(range(num_episodes), desc=\"학습 진행률\")\n",
    "\n",
    "for episode in progress_bar:\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    path = [env.current_pos]  # 시각화를 위해 절대 좌표 저장\n",
    "    step = 0\n",
    "\n",
    "    while not done and step < env.max_steps:\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randint(0, 7)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = model(state)\n",
    "                action = torch.argmax(q_values).item()\n",
    "\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32).to(device)\n",
    "        total_reward += reward\n",
    "        path.append(env.current_pos)  # 시각화를 위해 절대 좌표 추가\n",
    "\n",
    "        replay_buffer.add(state, action, reward, next_state_tensor, done)\n",
    "        state = next_state_tensor\n",
    "\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            batch, idxs, is_weights = replay_buffer.sample(batch_size)\n",
    "            states, actions, rewards_batch, next_states, dones = zip(*batch)\n",
    "            \n",
    "            states = torch.stack(states).to(device)\n",
    "            actions = torch.tensor(actions).to(device)\n",
    "            rewards_batch = torch.tensor(rewards_batch, dtype=torch.float32).to(device)\n",
    "            next_states = torch.stack(next_states).to(device)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
    "\n",
    "            q_values = model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "            next_q_values = target_model(next_states).max(1)[0]\n",
    "            target = rewards_batch + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            loss = (is_weights * nn.MSELoss(reduction='none')(q_values, target)).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            errors = torch.abs(q_values - target).detach().cpu().numpy()\n",
    "            replay_buffer.update(idxs, errors)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    if done:\n",
    "        path_length = len(path)\n",
    "        path_lengths.append(path_length)\n",
    "    else:\n",
    "        path_lengths.append(env.max_steps)\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "    progress_bar.set_postfix({'Reward': total_reward, 'Path Length': path_lengths[-1]})\n",
    "\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    if episode % 20 == 0:\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "    # 중간 경로 시각화 및 이미지 저장\n",
    "    if episode % 100 == 0 and episode > 0:\n",
    "        print(f\"Episode {episode} - 중간 경로 시각화 (Start: {start_pos}, End: {end_pos})\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(grid, cmap='gray', origin='upper')\n",
    "        path_rows = [pos[0] for pos in path]\n",
    "        path_cols = [pos[1] for pos in path]\n",
    "        plt.plot(path_cols, path_rows, 'r-', linewidth=2)\n",
    "        plt.plot(start_pos[1], start_pos[0], 'go')\n",
    "        plt.plot(end_pos[1], end_pos[0], 'bo')\n",
    "        plt.title(f\"Path Visualization at Episode {episode}\")\n",
    "        \n",
    "        save_path = os.path.join(save_dir, f\"episode_{episode}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"이미지 저장: {save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "# 12. 모델 저장\n",
    "torch.save(model.state_dict(), r'C:\\baramproject\\trained_model\\sibal12\\navigation_model_3.pth')\n",
    "print(\"모델이 'navigation_model_3.pth' 파일로 저장되었습니다.\")\n",
    "\n",
    "# 13. 학습 결과 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rewards, label='Total Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Learning Reward Graph')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(path_lengths, label='Path Length')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Path Length')\n",
    "plt.title('Learning Path Length Graph')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 14. 최적 경로 시각화 함수\n",
    "def plot_path(path, start_pos, end_pos, grid):\n",
    "    path_rows = [pos[0] for pos in path]\n",
    "    path_cols = [pos[1] for pos in path]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(grid, cmap='gray', origin='upper')\n",
    "    plt.plot(path_cols, path_rows, 'r-', linewidth=2, label='Optimal Path')\n",
    "    plt.plot(start_pos[1], start_pos[0], 'go', label=f'Start {start_pos}')\n",
    "    plt.plot(end_pos[1], end_pos[0], 'bo', label=f'End {end_pos}')\n",
    "    lon_ticks = np.linspace(0, n_cols, 8)\n",
    "    lon_labels = np.linspace(120, 127, 8)\n",
    "    plt.xticks(lon_ticks, [f\"{lon:.1f}°E\" for lon in lon_labels])\n",
    "    lat_ticks = np.linspace(0, n_rows, 9)\n",
    "    lat_labels = np.linspace(38, 30, 9)\n",
    "    plt.yticks(lat_ticks, [f\"{lat:.1f}°N\" for lat in lat_labels])\n",
    "    plt.xlabel('Longitude Grid')\n",
    "    plt.ylabel('Latitude Grid')\n",
    "    plt.title('Optimal Navigation Path')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 최적 경로 시각화\n",
    "plot_path(path, start_pos, end_pos, grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
